---
layout: default
title: Kafkaì— ëŒ€í•œ ê³ ì°°
date: 2022-12-19
parent: ðŸ“Œ Server
---


1. Request-response (HTTP) vs. event streaming (Kafka) ì •ë¦¬ ê¸€
[Use Cases and Architectures for HTTP and REST APIs with Apache Kafka](https://www.confluent.io/blog/http-and-rest-api-use-cases-and-architecture-with-apache-kafka/)

2. event streaming 2
[Event Sourcing](https://www.confluent.io/blog/event-sourcing-cqrs-stream-processing-apache-kafka-whats-connection/)

íŽ˜ì´ìŠ¤ë¶ê°™ì€ ê²½ìš°, ìœ ì € í”„ë¡œíŒŒì¼ì„ ë³€ê²½í–ˆì„ ë•Œ ì—¬ëŸ¬ ë‹¤ë¥¸ì„œë²„ë“¤ê³¼ ì—°ë™ì´ ì¼ì–´ë‚œë‹¤. ì´ëŸ¬í•œ ì„œë²„ë“¤ì€ ì„œë²„ ìž…ìž¥ì—ì„œ ë°”ë¡œ ìœ ì €ì—ê²Œ ë°˜í™˜í•˜ì§€ ì•Šì•„ë„ ëœë‹¤.
> Letâ€™s take an example. Consider a Facebook-like social networking app (albeit a completely hypothetical one) that updates the profiles database **when a user updates their Facebook profile**. There are several applications that need to be notified when a user updates their profile â€” the **search application** so the userâ€™s profile can be reindexed to be searchable on the changed attribute; the **newsfeed application** so the userâ€™s connections can find out about the profile update; the data warehouse **ETL application** to load the latest profile data into the central data warehouse that powers various analytical queries and so on.


> Event sourcing involves changing the profile web app to model the profile update as an event â€” something important that happened â€” and write it to a central log, like a Kafka topic. In this state of the world, all the applications that need to respond to the profile update event, merely subscribe to the Kafka topic and create the respective materialized views â€“ be it a write to cache, index the event in Elasticsearch or simply compute an in-memory aggregate. The profile web app itself also subscribes to the same Kafka topic and writes the update to the profiles database.
